\chapter{Inter-node challenges: distributing software artefacts}
\label{ch:softArtDist}
%We discussed in the previous chapters how the IoT will have a huge impact in our everyday activities.
%As a result, the presence of IoT devices in our environment will form a typical distributed system, on which we aim to deploy applications and maintain them in an updated state, as well as stop or remove them if desired.
%Some challenges raised by this dynamic behaviour were already exposed in the previous chapter, concluding by the proposal of a model@runtime as an abstraction and management approach for the software layer.
%As illustrated previously, managing evolution of this software layer is a major issue.
%In the software engineering community, software reconfiguration are realized through various techniques such as: service oriented computing  \cite{papazoglou2003service}, component oriented computing  \cite{szyperski1999component} or models@runtime  \cite{morin2009}  to achieve behaviour evolution of a distributed system.
Throughout this thesis, we have noticed three important characteristics of IoT systems: (1) they are distributed, (2) they include resource constrained nodes especially in memory and energy and (3) they are heterogeneous both in hardware infrastructure and role in the network. 
Indeed, the heterogeneity is an important factor as it encompasses the hardware and software layer: each node composing the network has its own role in it, and thus its specific hardware and software configurations which will evolve over time.
As we presented in the introduction of chapter \ref{ch:MARContiki}, solutions from the domain of Software Engineering can deal with this problem, but cannot be seamlessly adapted to fit with all the characteristics of an IoT system, especially with the resource constrained nodes.
Therefore, a first approach is to propose a way to decompose this systems into components, leveraging the benefits argued by CBSE. This was already discussed in the previous chapters, showing that a model@runtime can represent this decomposition in the model.
However, decompose this software in components raise the question about their distribution in a typical IoT network.

As a consequence, in this chapter we will address the following scientific problem: \textbf{How to \textit{efficiently} distribute, deploy and configure software components for IoT devices?}

Following our initial experiments presented in the chapter \ref{ch:MARContiki}, our M@R implementation provides an abstraction layer (which is simpler and safer to manipulate than the actual system) to tame the complexity of software adaptation in a distributed system. 
The software layer is represented as a set of interconnected components which are then deployed and configured on each node.
Following this approach, deploying and reconfiguring software requires distributing the code of the specific software components to the targeted nodes.
Currently, state of the art approaches to disseminate code over the air are limited in their ability to select specific targets (they disseminate the same binary to every node in the network \cite{hui2004dynamic}), and thus waste energy when all nodes do not present an homogeneous software layer.
Another approach called FiGaRo \cite{mottola2008figaro} propose the use of rules to filter nodes regarding its use or current capacities, in order to select some of them for an update or new deployment, thus a fine selection of an specific node becomes complicated.

In this chapter, we present an extension on the use of models@runtime to represent both the network and the application layer of the Internet of Things systems.
At runtime, we leverage these models through a new algorithm to distribute a software component only to those devices that need it, providing a fine selection by manipulating the model directly.
Moreover, this new algorithm aims at minimizing energy consumption during the whole reconfiguration and adaptation step, proposing a distribution mechanism which performs this task in a very efficient manner.

%After an overview of our current approaches,  we explain how the minimalistic Kevoree component model was implemented, followed by the main challenges while distributing the actual components in a binary form.
%Afterwards, a study of the possible distribution mechanisms is done, concluding with the proposition of a new algorithm for components distribution.
%Finally, our representative experiments are conducted on the FIT-IoT Lab testbed, in order to evaluate the algorithms and show our results regarding energy consumption and time to deploy such components.

\section{Inter-node challenges}
When changes in the model are disseminated in the IoT system, each node will adapt its local state to the new requirements. 
Indeed, this adaptation can include the deployment of one or several new components, as depicted in Figure \ref{fig:MAROverview2}. 
Moreover, a given component is not necessarily needed by all nodes in the network. 
Is in this part where state of the art algorithms to disseminate code over multi-hop WSNs are limited, since their ability to target specific nodes is poor or inexistent. 
For instance, the Deluge protocol \cite{hui2004dynamic} disseminates the same "data pages" of a whole firmware to every node, thus there is no fine selection of the nodes we want to upgrade. 
In order to deal with this limitation, we propose a new algorithm called \emph{Calpulli}, to efficiently perform the wireless distribution of components to the destination nodes. 
We leverage \textit{(a)} the routing properties of the running system and \textit{(b)} the information provided by the model to find the best strategy of components downloading.

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.95\columnwidth]{chapters/inter-node.images/MAR_Overview2.pdf}
	\caption{Model@runtime principle} \label{fig:MAROverview2}
\end{figure}

%This leaded our experimentations to a large set of nodes using the Cooja \cite{osterlind2006cross} simulator, in order to have a more controlled network topology which allows to compare the performance of our protocol.

We can summarize the contributions of this chapter as follows:
\begin{itemize}
	\item \textbf{Leverage the already described modelling tools to configure and re-configure IoT systems.} This approach provides a view of a running Internet of Things system on its current state and an efficient way of reconfiguring the software layer of these systems.
	\item \textbf{An energy efficient algorithm to disseminate software components.} This algorithm leverages the network topology and the information contained in the model to decide locally on the best way to disseminate software components.
	\item \textbf{An evaluation of the algorithm on a network of real sensor nodes.} The main experiment aims at evaluating the energy consumption of software reconfigurations using our approach on a network of real sensors using the IoT-lab platform.
\end{itemize}


The next section will present our proposition to divide an IoT application into components, following the component model proposed on the kevoree meta-model.
%Throughout this chapter, which are followed by the extensive simulation on Cooja showing the scalability of our approach.

%\section{Overview}

\section{Componentization of applications in the IoT}
One of the main challenges discussed on this chapter consists in decomposing IoT applications into smaller pieces in order to ease development and maintenance.
Several approaches have already proposed component models for embedded systems \cite{friedrich2001survey} and WSN  \cite{marron2006flexcup},  \cite{grace2004gridkit},  \cite{mottola2008figaro},  \cite{cid2012looci},  \cite{taherkordi2013optimizing}, on which the concepts already discussed in \ref{sec:CBSE} are leveraged to bring reconfiguration facilities onto this architectures.
Indeed, many similarities can be found between embedded systems, WSN and the IoT, mostly on the resource constrained nodes being part of these networks.
However, the network size, used protocols and applications complexity in IoT systems demand a different approach.

Our proposition based on a Model@runtime \cite{morin2009mar} presented in section \ref{sec:MAR_overview}, a paradigm which aims at simplifying the development of distributed dynamically adaptable systems, proposes the use of a model which represents the system state as depicted in Figure \ref{fig:MAROverview2}. 
This model can then be synchronized with the real running system: 
\begin{itemize}
	\item any change in the system state is reflected into the model,
	\item any change in the model will be sent to the running system which will adapt its behaviour to reflect these changes. 
\end{itemize}
These two way synchronization can be done automatically or on demand.

Model@runtime is generally used together with a component based software architecture.
In component based software architecture, an application is broken into different software pieces called software components which are linked together through software connectors  \cite{dashofy2002infrastructure,medvidovic2000classification,van2000koala} to from the architecture of the application.
Software components can then be deployed independently at remote locations as illustrated in Figure \ref{fig:MAROverview2}. 
One of the benefits is that it facilitates the management of dynamic applications, which is a primary concern for IoT systems deployed in constantly evolving environments.



When using component based software architecture together with the model@runtime paradigm, the model layer represents the software architecture (a set of software components and connectors) mapped on the distributed physical execution environment.
Any change made in the software architecture triggers an adaptation on the real system in order to deploy, remove or update software components or connectors.   

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.95\columnwidth]{chapters/inter-node.images/componentModel.pdf}
	\caption{Kevoree component model} \label{fig:kevCompModel}
\end{figure}

Our component model can be represented as depicted in figure \ref{fig:kevCompModel}, on which the properties of a component are separated as follows:
\begin{itemize}
	\item \textit{Kevoree Component.} The instance itself containing the life-cycle events triggered either by an external event (through the Kevoree-IoT core) or by an internal adaptation (which will modify the model).
	\item \textit{Properties.} Internal properties or parameters are the configurable settings that modify the component's behaviour
	This properties are represented by a dictionary, which can be affected by an \textit{update} event.
	\item \textit{Ports.} In contrast with other component models, an extra abstraction for component's interaction is provided by our model.
	It consists in exposing the ports (interfaces) only to another instance called \textit{channel}, on which communication means are implemented in a separated way.
	\item \textit{Channel.} An independent instance which is very useful to avoid direct function calls between components.
	Indeed, instead of using direct function calls, a communication channel can apply different and more complex semantics, a valuable feature in distributed environments \cite{fouquet2013kevoree, barais2005construire}.
	\item \textit{Binding.} Is the representation of the connections between channels. Several bindings can exist per channel, in a point-to-multipoint schema.
\end{itemize}

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.95\columnwidth]{chapters/inter-node.images/ComponentModelUML.pdf}
	\caption{Component model from the Kevoree meta-model} \label{fig:kevCompModelUML}
\end{figure}

As for the Kevoree meta-model representation, we can observe in figure \ref{fig:kevCompModelUML} that a component instance can use an unlimited number of ports which can also have an unlimited number of bindings.
We can clearly identify a channel as a separated instance, thus the implementation is completely independent from the component.
Moreover, the dictionary abstraction allows to configure both channels and components, adding flexibility to the communication means.

\subsection*{A component-based implementation for Contiki}
\label{subsec:contikiCompModel}
The implementation of this component based model was done by mapping the abstract concepts into data structures, as a part of a Contiki loadable module.
We leverage the Contiki's dynamic loader and linker feature described in  \cite{dunkels06runtime}, as a method to load dynamically the components and create its instances.
Indeed, a Contiki process is used to register new components to the Kevoree-IoT core, which are then available in the form of deploy units.
Afterwards, once the loading is completed, we can affect the life-cycle of the application by creating new instances of the newly downloaded type.
Instance creation is done using a simple memory block allocation scheme, allowing to create as many instances as free memory is available.

This adaptation of the component model, even if it is very oriented to its use in a Contiki environment, was optimized to achieve a behaviour very similar to the original Kevoree implementation, which is very high resource consuming.
Indeed, this task was very challenging due to the constrained resources of the nodes on which we aim to run our experiments.
Moreover, a more challenging problem raised while we tried to distribute components across the network.
While using a straightforward technique to reach the target node of a component, which consisted in a direct deploy unit download from a remote repository, we realized that this method was very energy consuming.
Indeed, every time a component was needed a considerable quantity of nodes in the mesh network were used to transport the packets to its final destination, and this was repeated for each node.
Thus, the new challenge lies in the way a component is disseminated on the network.
Indeed, providing the best path to download it and using local "cache" repositories to distribute a common component for several nodes could reduce energy consumption.
Therefore, a new distribution algorithm is needed in order to provide such functionality.
Details of this algorithm are discussed in the next section.

%\section{Requirements for artefacts distribution}
\section{Calpulli: A distributed algorithm for component dissemination}
In this section we present \textit{Calpulli}, an algorithm designed to properly distribute software components in the IoT.
It is then possible to provide a better component distribution to the targeted nodes, thanks to the available information, both the execution state of the system (in the M@R) and routing details of the mesh network.
The goal is to reduce redundant retransmission of identical information by caching, choosing the best node in the network on which we can store a requested component.
Thus, with the use of \textit{Calpulli}, we are able to save energy while distributing components (by reducing the retransmissions).
The two needed features by \textit{Calpulli} are described as following:
\paragraph{Routing properties of the running system.} Networks used by IoT systems are often referred to as Low power and Lossy Networks (LLNs). The Routing Protocol RPL \cite{rfc6550} is a IPv6 routing protocol for LLNs that builds a tree for routing, more precisely a Destination Oriented Directed Acyclic Graph (DODAG). This graph starts at the root/BR (Border Router), a specific node chosen by the system administrator and connected to the rest of the wired network. Each node in the graph has a rank that represents the number of hops to the root. In this hierarchy each node on the graph has a routing entry towards its parent and it can send a data packet to the BR by forwarding it to its immediate parent. Figure \ref{fig:MARdodag} gives an example of a simple DODAG within a 9-nodes network.

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.98\columnwidth]{chapters/inter-node.images/MAR_dodag.png}
	\caption{Dissemination of software components using a DODAG} \label{fig:MARdodag}
\end{figure}

\paragraph{Information provided by the model@runtime.} The model describes all the components of all the nodes in the network.
After a model synchronization, a node knows which components must be downloaded from the remote repository for its own adaptation.
Moreover, the information available on the model allows a wide introspection on the current deployment, thus it is possible to know which other nodes are requesting the same component, if any.
In the example shown on Figure \ref{fig:MARdodag}, the component represented by the $\bigstar$ is needed by nodes identified as 2-3-5-7-8-9. 
As an example, thanks to the model information, node 9 knows that the component $\bigstar$ is requested by nodes 2-3-5-7-8.

The objective of \emph{Calpulli} can be summarized as follows:
\begin{itemize}
	\item When the model has changed, the topology is used to identify how the components will be propagated, and where they will be cached, by parsing the model and looking for nodes requesting the same component ($\bigstar$ in Figure \ref{fig:MARdodag}).
	Once it is located, \textit{Calpulli} will mark it as a temporary caching node.
	\item This selected node (the node 2 in our example, called the \emph{repository node}) downloads the component and acts as a local repository for other nodes (nodes 3-5-7-8-9).
	\item All nodes will perform the same steps, and since the model and routing information is the same all of them will select the same node as repository.
	Thus, they will wait for the repository node until it is ready to provide the component $\bigstar$.
\end{itemize}

The selection process of the repository node for the component $\bigstar$ uses the hierarchical structure of the DODAG, available in the routing information (RPL storing mode). 
When a node needs the component $\bigstar$ in our example, two cases can occur:

\begin{enumerate}
	\item \textbf{A node determines itself as a repository.} This happens by comparing the topology and the model, when it is found that more than 2 children need the same component.
	Thus, the node will wait for the children component requests.
	\item \textbf{A node determines that it needs a component.} If the node does not act as a repository, but find that a component is needed, it will just send a component request to its parent. Its parent, if it is not a repository, will forward the request to its own parent, and so on until reaching the main repository, outside the local network.
\end{enumerate}

%As the algorithm will run asynchronously on each node, this two cases will incur in a race condition.
Thus, when a node which was not marked as a repository receives a message from a child node asking for a component, it just forwards the message to its immediate parent without modification.
In contrast, when the node is marked as a repository node and receives a component request, it will store the address of the requesting node in a queue.

\textit{Calpulli} can also determine that no node can be a repository candidate.
Therefore, the component request will reach the Border Router, which will forward the request to the main repository.
This main repository will act as a repository node, and it will also store the requesting node's addresses in a queue.
%Details about the use of Calpulli to download new artefacts are given in the next Subsection.

%\subsection{Downloading artefacts using Calpulli}
The implementation of \textit{Calpulli} was integrated as a part of the Kevoree-IoT runtime, which leverage the available UDP sockets on Contiki to transport a component from a remote repository located on the Internet.
Indeed, a small protocol was developed to support \textit{Calpulli}'s downloading mechanisms, in order to establish synchronization between nodes acting either as \textit{"repositories} or \textit{"clients"}.
This protocol aim to use the node address determined by \textit{Calpulli} as a repository, and also to transform any node into a repository if \textit{Calpulli} determines it.

\begin{figure}[]
	\centering
	\includegraphics[width=0.98\columnwidth]{chapters/inter-node.images/calpulliProtocol.pdf}
	\caption{State diagram describing a new component download, acting as a repository} \label{fig:calpulliProtocol}
\end{figure}

In Figure \ref{fig:calpulliProtocol}, a state-transition diagram is used to represent the details of the proposed protocol for components downloading.
As we can observe, once \textit{Calpulli} has determined the nearest repository candidate, an artefact request is sent to such node which will first determine if the artefact location is known (if the requested deploy unit was already downloaded). 
Afterwards, if the location is unknown, it will ask directly to the main repository (a central repository somewhere on the Internet).
When the location is known (deploy unit downloaded), a summary is sent to the \textit{"client"}, indicating details about the size and number of chunks that will be sent.
Afterwards, the server will receive a response asking for the chunks composing the deploy unit.
When the download is over the node stops the protocol and will look for the next request in the queue, if any.

In order to evaluate \textit{Calpulli}, a series of experiments was carried on.
The goal is to assess the energy savings provided by the algorithm, in comparison with state of the art algorithms for firmware updates, as well as the time needed to perform such updates.

%\subsection{First approach: Kevoree algorithm}

%\subsection{Particularities of a typical IoT network topology}

\section{Empirical evaluation}
In this section, we evaluate the performance of the \textit{Calpulli} algorithm with respect to energy consumption and delay to distribute software components.
The energy consumption is related to the amount of transmissions on all nodes in the mesh network, since a data packet can be retransmitted by several nodes before reaching its destination.
The time to deploy covers the delay between an artefact request and the deployment of the requested component.
We have evaluated our algorithms on a representative scenario taken from a real deployment scenario.
Indeed, our algorithm was implemented in the IoT-Lab testbed  \cite{Fleury15iotlab} with a specific configuration of 10 nodes, as a starting point.
While the availability of a huge number of nodes in a testbed seems to be adequate for a large deployment experiment, some difficulties were encountered during experimentation, regarding the network topology and routing protocols restrictions.
This is due to the layout of the physical deployment on the testbed, since the nodes are too close to each other, making difficult to build a mesh with several hops.
Therefore, modifications to the transmission power and sensibility of the radio interfaces have been done, in order to have a good topology to run the tests.
As for the routing protocols, we used ContikiRPL \cite{tsiftes2010contikirpl}, an implementation of the RPL \cite{rfc6550} protocol for LLNs and 6loWPAN.
This protocol triggers regularly a "rebuilding" of the topology, thus parents and children can change even if the nodes do not move.
Indeed, this modification can change the behaviour of our algorithm, thus our experiments must be run several times using the same configurations.
Even so, the representative results on 10 nodes show that our approach performs better regarding energy efficiency and deployment time in comparison to state of the art algorithms.

\subsection{Use case}
In our scenario, 10 selected nodes on the IoT-Lab testbed are preloaded with a firmware containing \textit{Kevoree-IoT}, \textit{Calpulli} and a UDP client/server which will act as a components repository when needed.
Moreover, a set of components were available on a central repository running on a PC, which was interfaced with the testbed through a SSH tunnel to a border router. This PC is representing the main repository available on Internet, thus external to the IoT network.

Our goal for this use case is to answer the following research questions: 
\paragraph{RQ1}: Does \textit{Calpulli}, our dedicated software components distribution algorithm, consumes less energy in average than state of the art algorithms for firmware/components distribution?

\paragraph{RQ2}: Is \textit{Calpulli} quicker to distribute software components than state of the art algorithms?

\subsection{Experimental setup}
This evaluation is based on experiments done with a set of physical nodes presented in the previous Subsection.
All the experiments described in this section have been carried out on the IoT-Lab testbed \cite{Fleury15iotlab}.
% already described in \ref{sec:iotlab}.
%IoT-Lab is a platform that aims to provide a full IoT environment, from very small nodes (based on msp430 MCU) to very big nodes (based on Cortex-A9 CPU), including a "middle" sized node (based on Cortex-M3 MCU).
Indeed, our experiments are designed to fit a "class 2" sized node, which is called "iot-lab M3" on this platform.
The choice of this node is done based on precedent analysis of performance in different nodes  \cite{tsekoura2014evaluation}, providing the best trade-off between overall energy consumption and hardware capabilities.

In this evaluation, we consider two base line algorithms to compare our results:
\begin{itemize}
	\item \textbf{Deluge:} Already described in Section \ref{subsec:deluge}, it is an epidemic dissemination protocol  \cite{hui2004dynamic} which aims to distribute a "large data object" (\textit{i.e.} larger that cannot fit into node's RAM) on WSNs. To manage the data size, an object is divided into elementary pages. A page is the basic unit of dissemination process and allows incremental upgrades. This protocol guarantees the distribution of exactly the same file to all nodes.
	\item \textbf{Kevoree:} the straightforward protocol used by the Kevoree framework  \cite{fouquet2013kevoree} in the Java implementation which is agnostic of the network topology. 
	This algorithm considers each node independently and each node will separately download the software components which should be installed from the main repository on Internet.
\end{itemize}

In the two algorithms, a node will use all necessary hops to reach the main repository, contributing to the overall energy consumption during the adaptation step.

For our evaluation, we are interested in this two different variables:
\begin{itemize}
	\item\textbf{Energy consumption}.
	It is measured using the tools provided by IoT-Lab. 
	The power used by each node is sampled every 100ms, thanks to a dedicated chip (INA226 current/power monitor) installed on the control board of every node.
	For a node's power consumption, the instantaneous power $P_i$ is sampled by the control node $n$ times for a given time $t_i$.
	Thus, the total consumption in the interval $\left[t_0, t_n\right]$ is given by the following equation:
	
	\begin{equation}
	\hspace*{\stretch{1}}
		\sum_{i=0}^{n-1}{\left( (t_{i+1} - t_i) \frac{P_{i+1} + P_i}{2} \right)}
	\hspace*{\stretch{1}}
	\end{equation}
	%Si quieres otra forma $\sum_{i=0}^{n-1}{\left( (t_{i+1} - t_i) \dfrac{e_{i+1} + e_i}{2} \right)}.$ Mira comoesto esta empotrado en el texto.
	then a mean value for all nodes is calculated to obtain the overall consumption for that experiment.
	\item\textbf{deployment time}.
	It is considered in the same way as the energy consumption, from the beginning of the adaptations until the system is executing all the component instances described on the new model.
\end{itemize}

Our experiments consider a fixed number of nodes, but the network topology varies between each experiment.
Moreover, we also vary the number of components to distribute, in order to evaluate the impact of this variable on the three algorithms (Deluge, Kevoree and Calpulli).
We developed four different components, compiled as Contiki ELF modules as described in \ref{subsec:contikiCompModel}.

As the topology of the RPL tree (DODAG) is hard to control within the IoT-Lab testbed, we have repeated each experiment 5 times to reduce any bias introduced by the random topology.
For all the experiments concerning \textit{Calpulli} and the Kevoree algorithm, we have generated 10 different models (configuration including which component has to be installed on which node) for a given number of components (1 to 10).
Thus, in the models, the quantity of components will be distributed among the 10 represented nodes, choosing randomly one of the four available on the modelled repository.
Moreover, the nodes where the components are distributed have been chosen randomly to reduce any bias in the experiment.
A total of 100 models were generated for the experiments

As for Deluge,  a simple Contiki ELF file was produced to represent a component to be disseminated in some selected nodes, using the implementation already available in Contiki.
Since Deluge does not offer any guidance for the deployment, we selected and configure the same ten nodes to receive the disseminated ELF file.
A sink node was also configured to provide the ELF files, acting as a main repository.
Indeed, we decided to use a node as a repository, since a UDP server cannot be accessed by deluge, unless the server is also running Deluge.
Since Deluge is not intended to run on big machines, where our UDP server is running, the best way to provide the components is to configure a single node as a repository.

The next Subsection will discuss the power needed to deploy artefacts using the described protocols. 

\subsection{Evaluation of power consumption}
For our first test, we evaluated Deluge.
When we tried to disseminate only one component to only one node, the protocol was very slow, exceeding the time given to our experiment (20 minutes) before the component was deployed. After several tests, 3 components out of 10 were correctly deployed, when selecting 10 nodes to be part of the deployment.
With this behaviour, Deluge seems to be very slow, with a very high energy consumption in the dissemination step. The consumption being too high, and the deployment unfinished for the given experiments, Deluge is not included in the results graphs.

The experiments for the Kevoree basic protocol and Calpulli, from 1 to 10 components deployed, were conducted as follows:
\begin{enumerate}
	\item A generated model is chosen for a given quantity of components.
	\item That model is deployed in the network and the adaptations take place.
	\item The experiment is over when all the components are installed and running.
	\item This is repeated 5 times, using a different model for the same quantity of components.
\end{enumerate}

A total of 50 experiments were conducted for each algorithm.

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.95\columnwidth]{chapters/inter-node.images/energyWithFonts.pdf}
	\caption{Energy consumption in the whole network for the given components} \label{fig:Energy}
\end{figure}

The results of these experiments can be observed in Figure \ref{fig:Energy}, where we acknowledge a reduction in the overall consumption when more than 5 components are deployed.
Indeed, differences around 50 joules can be highlighted. 

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.95\columnwidth]{chapters/inter-node.images/timeWithFonts.pdf}
	\caption{Time to deploy the selected components} \label{fig:Time}
\end{figure}

\subsection{Evaluation of deployment time}

The time to deploy was also evaluated as a part of a trade-off given by the delay of the analysed protocols.
In the case of Deluge, as we already state in the previous evaluation, the time to deploy is too high, having only 3 nodes out of 10 working correctly, after the 20 minutes given to the experiment.
For the Kevoree and \textit{Calpulli} algorithms, we can observe in Figure \ref{fig:Time} that the time is approximately the same for 2 and 4 components.
After the fifth component, the time to deploy begins to increase. Since \textit{Calpulli} has a delay in time before downloading the components, caused by the time used to resolve whether it is a repository or not, there is a trade-off between this and the gain in energy consumption. We argue that for larger networks the benefits could be more considerable. We discuss this on the next Section.

\section{Theoretical evaluation}
After an empirical evaluation of \textit{Calpulli}, we needed to know if the tendency towards a better performance in energy consumption still there in bigger networks than 10 nodes, the subject of our first evaluation.
However, the conducted experiments to get our first results needed a special configuration and set of nodes in order to create a stable RPL network.
This is very time consuming while scaling our approach for more nodes, besides the technical challenges when larger models need to be parsed by the constrained nodes.
Indeed, even if the M3 node is able to de-serialize big models, the implementation of the current model parser needs to be enhanced, which is a different challenge out of the scope of our main scientific problem.
Therefore, this section proposes a theoretical evaluation based on a very simple model of content caching, which is the main purpose of \textit{Calpulli}.
The goal is to assess the gain in energy by avoiding retransmissions, which is the most energy consuming task.

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.8 \columnwidth]{chapters/inter-node.images/grenoble-topology-m3.pdf}
	\caption{Topology of the IoT-Lab M3 nodes at the Grenoble site} \label{fig:GrenobleTopology}
\end{figure}

\subsection{Model of the IoT network}
One of the big challenges while evaluating \textit{Calpulli}, was to build a representative RPL network by selecting the right nodes depending on the distance and the place of the Border Router.
In this theoretical evaluation we propose a model of the existing topology of the Grenoble IoT-Lab testbed\footnote{\url{https://www.iot-lab.info/wp-content/uploads/2013/10/planMontbonnot.png}}, which is presented on figure \ref{fig:GrenobleTopology}.
This model will take into account all the M3 nodes present on the testbed represented by each blue point, including the physical distance between them shown in the axis of our figure (distance in meters), the radio capabilities (channel, range) and the possibility to simulate a RPL tree.

Once we represent our topology, we need to select a Border Router among the available nodes.
This was done by selecting a node which its position is the optimal to build the biggest RPL tree, with a maximum quantity of hops to the last connected node.
This is important to test an algorithm dedicated to distribute a specific content to a specific node, since our goal is to measure the performance on large multi-hop networks.

\begin{figure}[]
	\centering
	\includegraphics[width=0.8 \columnwidth]{chapters/inter-node.images/grenoble-sink-node.pdf}
	\caption{Selected node as a Border Router with a maximum of 9 hops} \label{fig:GrenobleSinkNode}
\end{figure}

Figure \ref{fig:GrenobleSinkNode} presents the selected node (node 59, big red point), which according to the model can build at least a 9 hops RPL tree.
From this node, we can select a subset of reachable nodes at the maximum quantity of hops (9), as shown in figure \ref{fig:GrenobleReachable}.
This subset is a reference to the possible RPL trees that can be formed by choosing nodes randomly, in order to change the topology.

\begin{figure}[]
	\centering
	\includegraphics[width=0.8 \columnwidth]{chapters/inter-node.images/grenoble-reachable-m3.pdf}
	\caption{Subset of reachable nodes from the sink} \label{fig:GrenobleReachable}
\end{figure}

\begin{figure}[]
	\centering
	\includegraphics[width=0.8 \columnwidth]{chapters/inter-node.images/grenoble-RPL.pdf}
	\caption{Theoretical RPL tree} \label{fig:GrenobleRPL}
\end{figure}

Figure \ref{fig:GrenobleReachable} illustrates a subset of nodes discussed above, while Figure \ref{fig:GrenobleRPL} shows the RPL tree built from this subset.
The next Subsection will show the results of the simulation with the presented topology and RPL tree.

\subsection{Experimental setup}
A subset of the topology is taken varying the max number of hops (from the sink), then in this sub-topology, the target "number of nodes" is selected: the number goes from 10 to the max number.
For each such number of nodes 100 experiments are run where that amount of nodes are selected randomly in the sub-topology (for example the sub-topology on figure \ref{fig:GrenobleReachable}).
For each experiment, the cost of unicast and the cost with caching are computed (= the number of necessary transmissions) with all nodes trying to get same identical content.
The distributed content is only one component, which is spread randomly between half of all available nodes.
It means that every node has a 50\% chances to deploy a component, which allows an approximative binary distribution of the content.
Disconnected nodes are not considered.

\subsection{Evaluation results}
Once our experimental setup is ready, the measurements while distributing a component on the previously modelled network took place.

\begin{figure}[]
	\centering
	\includegraphics[width=0.8 \columnwidth]{chapters/inter-node.images/nb-of-retransmitions-5.pdf}
	\caption{Number of retransmissions for 5 hops maximum} \label{fig:NumberOfRetransmission5hops}
\end{figure}

\begin{figure}[]
	\centering
	\includegraphics[width=0.8 \columnwidth]{chapters/inter-node.images/nb-of-retransmitions-10.pdf}
	\caption{Number of retransmissions for 10 hops maximum} \label{fig:NumberOfRetransmission10hops}
\end{figure}

Figure \ref{fig:NumberOfRetransmission5hops} shows how the cost of unicasting the component from a single source grows linearly, since the needed retransmissions will grow as the hops increase.
Indeed, the blue curve shows how the nodes need to retransmit a packet to the last possible hop every time the content (a component) is requested.
For instance, at the end of the curve we can observe that we can reach around 210 nodes while limiting our tree to 5 hops.
Then, the cost to send the content to half of the nodes grows to around 370 transmissions.
The variations are due to the fact that several nodes could be attached to the same parent, so the retransmission takes place only once per node, according to the chance of deploying such component.
Another example showing the same behaviour is shown in figure \ref{fig:NumberOfRetransmission10hops}

In contrast, using a simple caching technique, a node can store the content to retransmit it without requesting it again to the source.
Indeed, less transmissions are necessary to distribute the content to all concerned nodes, since each node which is storing the content can distribute it to its children.
We can observe that the number of transmissions is drastically reduced by using this method, and even more for a bigger network as the presented in figure \ref{fig:NumberOfRetransmission10hops}.

\begin{figure}[]
	\centering
	\includegraphics[width=0.8 \columnwidth]{chapters/inter-node.images/avg-cost-per-node-5.pdf}
	\caption{Average cost per node for 5 hops maximum} \label{fig:AvgCostPerNode5hops}
\end{figure}

With a view to give a deeper analysis, we can measure the average cost per node while trying to transmit a component.
This is done by taking the number of retransmissions divided by the quantity of nodes, in order to get an average cost per node depending on the quantity of hops.
Indeed, while transmitting a component to a fixed quantity of hops and a fixed number of targets, the cost will be the division between them.
In our example, observable in figures \ref{fig:AvgCostPerNode5hops} and \ref{fig:AvgCostPerNode10hops}, we can see that the cost tends to the half of hops, since the target nodes are the half of the maximum reachable nodes (around 340).
The cost in unicast, for instance, in a maximum of 10 hops will be near to 5, which is the average distance in hops from the sink to the destinations.
But most important, we can observe that the cost with the simple caching technique tends to one.
It means that while using this technique a node needs to transmit the content only once, since it's being stored on the next hop, so no need to retransmit it again if it is requested by another node on the same path.

\begin{figure}[]
	\centering
	\includegraphics[width=0.8 \columnwidth]{chapters/inter-node.images/avg-cost-per-node-10.pdf}
	\caption{Average cost per node for 10 hops maximum} \label{fig:AvgCostPerNode10hops}
\end{figure}

\subsection{Conclusion}
These results show that an algorithm for content caching, in our case components, is still worth considering, since the energy savings can be huge compared to straightforward unicast protocols.
The code of this simulation is publicly available for further reference\footnote{\url{https://cloud.sagemath.com/projects/269f7823-e948-4bab-8e0b-999ae12c8685/files/TopologyAnalysis.html}}.
Indeed, \textit{Calpulli} performs a very similar algorithm using the knowledge of the model which contains the nodes requesting the same component (content).
Then, since the topology is also known, \textit{Calpulli} can determine which node is the best candidate to cache the requested component.
In this theoretical experiment, we can extrapolate the behaviour of \textit{Calpulli}, which we think will perform better in large networks than 10 nodes, as it was shown in our empirical evaluation, according to the results presented in this chapter.

However, we can not completely neglect the energy needed by a node to cache a component, which can variate according to the component's size.
Indeed, a deeper evaluation can be performed by also modelling the overall energy consumption of a node while transmitting and caching content.
This evaluation will be part of our perspectives.

\section{Conclusion}
This chapter presented how Kevoree-IoT, our model@runtime implementation, can be used to deal with the problem of software deployment and configuration in Internet of Things systems. 
The main contribution presented is \textit{Calpulli}, a decentralized algorithm which leverages model@runtime information together with the network topology to optimize the distribution of software components, regarding energy consumption and deployment time. 
We highlight that \textit{Calpulli} provides a very good trade-off between deployment time and energy consumption with respect to Deluge and the classical Kevoree algorithm.
Indeed, our current Kevoree-IoT implementation along with \textit{Calpulli}, can successfully distribute software components into an IoT network in an efficient manner.

Therefore, two things can be noticed on the execution of our approach:

\begin{enumerate}
	\item We provided a mechanism to distribute software components to specific nodes
	\item and an algorithm to efficiently distribute such components.
\end{enumerate}

With this contributions, we have added adaptation features to nodes being part of an IoT system.
Indeed, each node can perform different types of adaptations and change its behaviour regarding the execution state before a new model is disseminated in the network.

\subsection*{Results}
While evaluating \textit{Calpulli}, our results show that a trade-off exists between components distribution speed and the energy consumption, resulting in overall energy savings.
Indeed, in the empirical evaluation \textit{Calpulli} was able to save energy while caching content on intermediate nodes before reaching the actual concerned node.
Energy saving is very important in networks like the IoT, where the topology coupled with the energy constraints can determine the life-cycle of a node.
Moreover, our theoretical results show that algorithms such \textit{Calpulli} are very pertinent in networks with a huge quantity of nodes, especially on multi-hop mesh topologies.

These results are complemented by our theoretical evaluation, on which we argue that in bigger networks, \textit{Calpulli} will save even more energy, according to the number of hops needed to reach the source of components.